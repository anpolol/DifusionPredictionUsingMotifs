{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pickle\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from modules.support_functions import Utils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from modules.Modularity import RecursiveModularity\n",
    "\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "from littleballoffur import DegreeBasedSampler, \\\n",
    "    PageRankBasedSampler, \\\n",
    "    RandomEdgeSampler, \\\n",
    "    SnowBallSampler, \\\n",
    "    ForestFireSampler, \\\n",
    "    CommunityStructureExpansionSampler, \\\n",
    "    ShortestPathSampler, \\\n",
    "    RandomWalkSampler, \\\n",
    "    RandomWalkWithJumpSampler, \\\n",
    "    MetropolisHastingsRandomWalkSampler, \\\n",
    "    NonBackTrackingRandomWalkSampler, \\\n",
    "    CirculatedNeighborsRandomWalkSampler, \\\n",
    "    CommonNeighborAwareRandomWalkSampler, \\\n",
    "    LoopErasedRandomWalkSampler\n",
    "\n",
    "methods = [\n",
    "    # random node sampling\n",
    "    DegreeBasedSampler,\n",
    "    PageRankBasedSampler,\n",
    "\n",
    "    # Random Edge Sampling\n",
    "    RandomEdgeSampler,\n",
    "    SnowBallSampler,\n",
    "    CommunityStructureExpansionSampler,\n",
    "    ShortestPathSampler,\n",
    "    # Random-Walks Dased\n",
    "    RandomWalkSampler,\n",
    "    RandomWalkWithJumpSampler,\n",
    "    MetropolisHastingsRandomWalkSampler,\n",
    "    NonBackTrackingRandomWalkSampler,\n",
    "    CirculatedNeighborsRandomWalkSampler,\n",
    "    CommonNeighborAwareRandomWalkSampler,\n",
    "    LoopErasedRandomWalkSampler,\n",
    "    RecursiveModularity\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-diagnosis",
   "metadata": {},
   "source": [
    "**загрузка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_graphs.pickle','rb') as f:\n",
    "    graphs = pickle.load(f)\n",
    "\n",
    "#Загрузка распределения мотивов для полных графов\n",
    "X_full_f1 = numpy.load('DataHelp/motifs_matrix_full_f1.npy')\n",
    "X_full_f3 = numpy.load('DataHelp/motifs_matrix_full_f3.npy')\n",
    "X_full_nodif = numpy.load('DataHelp/motifs_matrix_full.npy')\n",
    "\n",
    "#Загрузка словарей распределения мотивов для сэмплов. \n",
    "\n",
    "with open('./DataHelp/motifs_samples_forMSE.pickle', 'rb') as f:\n",
    "        X_sample=pickle.load(f)\n",
    "with open('./DataHelp/motifs_samples_f1_forMSE.pickle', 'rb') as f:\n",
    "        X_sample_f1=pickle.load(f)\n",
    "with open('./DataHelp/motifs_samples_f3_forMSE.pickle', 'rb') as f:\n",
    "        X_sample_f3=pickle.load(f)\n",
    "#Каждый подграф кроме Modularity повторен 10 раз из-за стохастических методов. \n",
    "#Поэтому для одного экзмепляра надо взять первые 170 строчек (или вторые 170 стр и тд)\n",
    "\n",
    "X_sample_regression = dict(map(lambda e: (e[0], dict(map(lambda o: (o[0],o[1][:len(graphs)]),e[1].items()))),X_sample.items()))\n",
    "X_sample_f3_regression = dict(map(lambda e: (e[0], dict(map(lambda o: (o[0], o[1][:len(graphs)]), e[1].items()))), X_sample_f3.items()))\n",
    "X_sample_f1_regression = dict(map(lambda e: (e[0], dict(map(lambda o: (o[0], o[1][:len(graphs)]), e[1].items()))), X_sample_f1.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE уже подсчитанные можно загрузить\n",
    "with open('./DataHelp/MSE_methods_f1.pickle','rb') as f:\n",
    "    MSE_methods_f1=pickle.load(f)\n",
    "with open('./DataHelp/MSE_methods_f3.pickle','rb') as f:\n",
    "    MSE_methods_f3=pickle.load(f)\n",
    "with open('./DataHelp/MSE_methods_nodif.pickle', 'rb') as f:\n",
    "    MSE_methods_nodif=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-attack",
   "metadata": {},
   "source": [
    "**отрисовка MSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(MSE_dict, name_of_method):\n",
    "    MSE = pd.DataFrame(MSE_dict, columns=list(MSE_dict.keys()))\n",
    "    plt.figure(figsize=(20, 6))\n",
    "\n",
    "    plt.suptitle(name_of_method, fontsize=22)\n",
    "    plt.subplot(121)\n",
    "    plt.xlabel(\"number of nodes\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    g1 = sns.boxplot(data=MSE)\n",
    "    g1.set_yscale('log')\n",
    "    plt.subplot(122)\n",
    "    plt.xlabel(\"number of nodes\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    y = list(MSE.mean())\n",
    "    x = list(map(lambda x: int(x), list(MSE.columns)))\n",
    "    g2 = sns.scatterplot(x=x, y=y)\n",
    "    g2.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in MSE_methods_f1:\n",
    "    name_of_graph = name.split(\"'\")[0] + ' Motifs of different types. F1'\n",
    "    plot(MSE_methods_f1[name], name_of_graph)\n",
    "for name in MSE_methods_f3:\n",
    "    name_of_graph = name.split(\"'\")[0] + ' Motifs of different types. F3'\n",
    "    plot(MSE_methods_f3[name], name_of_graph)\n",
    "for name in MSE_methods_nodif:\n",
    "    name_of_graph = name.split(\"'\")[0] + ' Not different types of motifs'\n",
    "    plot(MSE_methods_nodif[name], name_of_graph)\n",
    "plt.figure(figsize=(10, 6))\n",
    "mean_MSEs = []\n",
    "for name in MSE_methods_f1:\n",
    "    MSE_dict = MSE_methods_f1[name]\n",
    "    MSE = pd.DataFrame(MSE_dict, columns=list(MSE_dict.keys()))\n",
    "    y = list(MSE.mean())\n",
    "    x = list(map(lambda x: int(x), list(MSE.columns)))\n",
    "    ax = plt.scatter(x=x, y=y)\n",
    "    plt.yscale('log')\n",
    "    mean_MSEs.append(sum(y) / len(y))\n",
    "\n",
    "plt.legend(['mean MSE. Motifs of different types. F1' + str(x[0]).split('.')[-1].split(\"'\")[0] + ': ' + str(np.round(x[1], decimals=3)) for x in\n",
    "            zip(methods, mean_MSEs)])\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 6))\n",
    "mean_MSEs = []\n",
    "for name in MSE_methods_f3:\n",
    "    MSE_dict = MSE_methods_f3[name]\n",
    "    MSE = pd.DataFrame(MSE_dict, columns=list(MSE_dict.keys()))\n",
    "    y = list(MSE.mean())\n",
    "    x = list(map(lambda x: int(x), list(MSE.columns)))\n",
    "    ax = plt.scatter(x=x, y=y)\n",
    "    plt.yscale('log')\n",
    "    mean_MSEs.append(sum(y) / len(y))\n",
    "\n",
    "plt.legend(['mean MSE. Motifs of different types. F3' + str(x[0]).split('.')[-1].split(\"'\")[0] + ': ' + str(\n",
    "    np.round(x[1], decimals=3)) for x in zip(methods, mean_MSEs)])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "mean_MSEs = []\n",
    "for name in MSE_methods_nodif:\n",
    "    MSE_dict = MSE_methods_nodif[name]\n",
    "    MSE = pd.DataFrame(MSE_dict, columns=list(MSE_dict.keys()))\n",
    "    y = list(MSE.mean())\n",
    "    x = list(map(lambda x: int(x), list(MSE.columns)))\n",
    "    ax = plt.scatter(x=x, y=y)\n",
    "    plt.yscale('log')\n",
    "    mean_MSEs.append(sum(y) / len(y))\n",
    "\n",
    "plt.legend(['mean MSE. Not different types of motifs.' + str(x[0]).split('.')[-1].split(\"'\")[0] + ': ' + str(\n",
    "    np.round(x[1], decimals=3)) for x in zip(methods, mean_MSEs)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-circus",
   "metadata": {},
   "source": [
    "**Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    res = executor.map(Utils.count, list(zip(*graphs))[1])\n",
    "\n",
    "y = []\n",
    "for n_iter in res:\n",
    "    y.append(n_iter)\n",
    "with open('DataHelp/names_of_all_motifs.pickle', 'rb') as f:\n",
    "    names_of_all_motifs = pickle.load(f)\n",
    "\n",
    "with open('DataHelp/names_of_all_motifs_diff.pickle', 'rb') as f:\n",
    "    names_of_all_motifs_diff = pickle.load(f)\n",
    "\n",
    "for method in methods:\n",
    "    name_of_method = str(method).split('.')[-1].split(\"'\")[0]\n",
    "    for n in list(range(l, r, step)):\n",
    "        X_f1 = X_sample_f1_regression[name_of_method]['Number of nodes: ' + str(n)]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_f1, y, test_size=0.3)\n",
    "        X_train = pd.DataFrame(X_train, columns=names_of_all_motifs_diff)\n",
    "        # Initialize CatBoostRegressor\n",
    "        model = CatBoostRegressor(iterations=100, silent=True)\n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        # Get predictions\n",
    "        preds = model.predict(X_test)\n",
    "        # SHAP explainer:\n",
    "       # explainer = shap.Explainer(model)\n",
    "       # shap_values = explainer(X_train)\n",
    "       # shap.plots.beeswarm(shap_values)\n",
    "        print('Motifs of different types, F1. Method: ', name_of_method, ' Number of nodes: ' + str(n), ' MAPE ',\n",
    "              Utils.mean_absolute_percentage_error(y_test, preds))\n",
    "\n",
    "        X_f3 = X_sample_f3_regression[name_of_method]['Number of nodes: ' + str(n)]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_f1, y, test_size=0.3)\n",
    "        X_train = pd.DataFrame(X_train, columns=names_of_all_motifs_diff)\n",
    "        # CatBoostRegressor\n",
    "        model = CatBoostRegressor(iterations=100, silent=True)\n",
    "        model.fit(X_train, y_train)\n",
    "        # Get predictions\n",
    "        preds = model.predict(X_test)\n",
    "        # SHAP explainer:\n",
    "        #explainer = shap.Explainer(model)\n",
    "        #shap_values = explainer(X_train)\n",
    "        #shap.plots.beeswarm(shap_values)\n",
    "        print('Motifs of different types. F3. Method: ', name_of_method, ' Number of nodes: ' + str(n), ' MAPE ',\n",
    "              Utils.mean_absolute_percentage_error(y_test, preds))\n",
    "\n",
    "        X = X_sample_regression[name_of_method]['Number of nodes: ' + str(n)]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "        X_train = pd.DataFrame(X_train, columns=names_of_all_motifs)\n",
    "        # CatBoostRegressor\n",
    "        model = CatBoostRegressor(iterations=100, silent=True)\n",
    "        model.fit(X_train, y_train)\n",
    "        # Get predictions\n",
    "        preds = model.predict(X_test)\n",
    "        #explainer = shap.Explainer(model)\n",
    "        #shap_values = explainer(X_train)\n",
    "        # summarize the effects of all the features\n",
    "        #shap.plots.beeswarm(shap_values)\n",
    "        print('Motifs. Not different types. Method: ', name_of_method, ' Number of nodes: ' + str(n), ' MAPE ',\n",
    "              Utils.mean_absolute_percentage_error(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
