{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affecting-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "\n",
    "#supernoder files:\n",
    "\n",
    "#вариант, который считает РАЗНЫЕ типы мотивов одного и того же размера\n",
    "from SuperNoder_diff_types.manager import Manager as Manager_types \n",
    "\n",
    "\n",
    "#вариант, который считает все мотивы одного размера вместе\n",
    "from SuperNoder.manager import Manager as Manager\n",
    "\n",
    "#!pip install ipyparallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-huntington",
   "metadata": {},
   "source": [
    "**First of all will convert every dataset to a txt file with nodes as numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "binary-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's choose graphs randomly. k - number of graphs\n",
    "for root, dirs, files in os.walk(r\"C:\\Users\\anpolol\\Desktop\\DifusionPredictionUsingMotifs\\Data\\reply_networks\"):\n",
    "    datasets_names = random.choices(files,k=128)\n",
    "    \n",
    "#in every graph there are 11 networks, all_nets consists of all nets  \n",
    "all_nets = dict()\n",
    "for dataset in datasets_names:\n",
    "    if dataset not in all_nets:\n",
    "        all_nets[dataset] = []\n",
    "        month_nets = json.load(open(r\"C:\\Users\\anpolol\\Desktop\\DifusionPredictionUsingMotifs\\Data\\reply_networks\\\\\"+str(dataset)))\n",
    "        all_nets[dataset]=all_nets[dataset] + month_nets\n",
    "        \n",
    "#Create txt files from json\n",
    "path=r'Data/'\n",
    "for dataset in all_nets:\n",
    "    name = dataset.split('.')\n",
    "    for i,net in enumerate(all_nets[dataset]):\n",
    "        \n",
    "        #Create nodes file\n",
    "        t=list(net.values())\n",
    "        nodes = (Counter([item for sublist in t for item in sublist] + list(net.keys()))) \n",
    "        map_nodes=dict(zip( nodes , list(range(len(nodes))))) #нумеруем ники\n",
    "        if not os.path.exists(path+name[0]+\"_\"+str(i)+\"_nodes\"+\".txt\"):\n",
    "            file_nodes = open(path+name[0]+\"_\"+str(i)+\"_nodes\"+\".txt\", \"w+\")\n",
    "            for j in range(len(nodes)):\n",
    "                file_nodes.write(str(j)+' A'+'\\n')\n",
    "            file_nodes.close()\n",
    "        \n",
    "        #Create edges files\n",
    "        if not os.path.exists(path+name[0]+\"_\"+str(i)+\".txt\"):\n",
    "            file= open(path+name[0]+\"_\"+str(i)+\".txt\", \"w+\") \n",
    "            for node in net:\n",
    "                for neigh in net[node]:\n",
    "                    file.write(str(map_nodes[node])+' '+str(map_nodes[neigh])+'\\n') #first node replied to the second    \n",
    "            file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-letter",
   "metadata": {},
   "source": [
    "**Some statistics for graphs**:\n",
    "- число узлов \n",
    "- плотность\n",
    "- к-т кластеризации (общий, для графа)\n",
    "- ассортативность (по степени)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "#построение графа из файла с ребрами\n",
    "print('Number of nodes (NN), Clustering coefficient (CC), Density(D), Degree assortativity coefficient(DAC) \\n')\n",
    "for dataset in all_nets:\n",
    "    print('DATASET: ', dataset,'\\n')\n",
    "    name = dataset.split('.')\n",
    "    number_of_nodes = []\n",
    "    clustering_coef=[]\n",
    "    density=[]\n",
    "    degree_assort=[]\n",
    "    for i,net in enumerate(all_nets[dataset]):\n",
    "        g = nx.read_edgelist(path+name[0]+\"_\"+str(i)+\".txt\",delimiter=' ', create_using=nx.DiGraph(), nodetype = int)\n",
    "        #число узлов \n",
    "        number_of_nodes.append(g.number_of_nodes())\n",
    "        #коэффициенты кластеризации ищутся следующим образом:\n",
    "        clustering_coef.append(np.mean(list(nx.clustering(g).values())))\n",
    "        #плотность\n",
    "        density.append(nx.density(g))\n",
    "        #ассортативность\n",
    "        degree_assort.append(nx.degree_assortativity_coefficient(g))\n",
    "    log = 'NN: {:.4f}, CC: {:.4f}, D: {:.4f}, DAC: {:.4f}'\n",
    "    print('mean: ', log.format(np.mean(np.array(number_of_nodes)) ,np.mean(np.array(clustering_coef)) ,np.mean(np.array(density)),np.mean(np.array(degree_assort))),'\\n')\n",
    "    print('std: ',log.format(np.std(np.array(number_of_nodes)) ,np.std(np.array(clustering_coef)) ,np.std(np.array(density)),np.std(np.array(degree_assort))),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-station",
   "metadata": {},
   "source": [
    "# **Motif counter - SuperNoder** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-committee",
   "metadata": {},
   "source": [
    "**arguments for SuperNoder:**\n",
    "\n",
    "-n,  --nodes-file <filename> MANDATORY The list of nodes. Node id and label for each row separated by a space\\\n",
    "-e,  --edges-file <filename> MANDATORY The list of edges. One edge for each row.\\\n",
    "-m,  --method <method> OPTIONAL The heuristic to use in order to maximize motifs. DEFAULT: h1 \\\n",
    "-tn, --type-of-network <type> OPTIONAL \tThe type of network. It can be chosen from [direct, undirect]. DEFAULT: undirect\\ \n",
    "-th, --threshold <threshold> OPTIONAL The threshold to hold over-represented motifs.\\\n",
    "-ms, --motif-size <size> OPTIONAL The size of motifs. It must be greater or equal to 3. DEFAULT: 3\\\n",
    "-h1tr, --h1-times-repetition <times> OPTIONAL \\tThe number of repetition of h1. DEFAULT: 1\\\n",
    "-ss, --samples-size <sample_size> OPTIONAL The size of samples for heuristics h4 and h5. DEFAULT: 100\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-amazon",
   "metadata": {},
   "source": [
    "# you should \"ipcluster start -n 4\" on your local machine\n",
    "**instead of 4 you should write the number of engines on your computer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "c = ipp.Client()\n",
    "dview = c[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting every netin a graph separately\n",
    "args_e=[]\n",
    "for dataset in all_nets:\n",
    "    name = dataset.split('.')\n",
    "    for i,net in enumerate(all_nets[dataset]):\n",
    "        args_e.append(path+name[0]+\"_\"+str(i)+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(arg_e):\n",
    "    from SuperNoder_diff_types.manager import Manager as Manager_types \n",
    "    arg_tn='direct'\n",
    "    arg_th = '1' \n",
    "    arg_m = 'h1'\n",
    "    arg_ss = '100'\n",
    "    arg_h1tr = 1 \n",
    "    name=arg_e.split('.')\n",
    "    arg_n = name[0]+\"_nodes\"+\".txt\"\n",
    "    distributions = {}\n",
    "    distributions_disjoint = {}\n",
    "    \n",
    "    for arg_ms in range(3,9):\n",
    "        argv=[' ','-e',arg_e, '-n',arg_n, '-tn',arg_tn,'-th',arg_th,'-ms',arg_ms,'-m',arg_m,\\\n",
    "      '-h1tr',arg_h1tr,'-ss',arg_ss]\n",
    "        m = Manager_types(argv)\n",
    "        distribution_disjoint, distribution_f1 = m.run()\n",
    "        distributions = dict(list(distributions.items()) + list(distribution_f1.items()))\n",
    "        distributions_disjoint = dict(list(distributions_disjoint.items()) + list(distribution_disjoint.items()))\n",
    "    return  arg_e,distributions_disjoint,distributions#первое значение словаря - тип мотива или размер мотива, второе значение - количество таких мотивов в графе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a parellelization\n",
    "res = dview.map(func,args_e).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distributions of motifs for every net:\n",
    "Motif_f1 = dict()\n",
    "Motif_f3 = dict()\n",
    "for (name,f3,f1) in res:\n",
    "    Motif_f3[name] = f3\n",
    "    Motif_f1[name] = f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-assistant",
   "metadata": {},
   "source": [
    "**составляем матрицу входных данных таким образом, чтоб она была одной и той же длины для любого датасета**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_of_all_motifs=[] #list of all motif types in all datasets\n",
    "for dataset in Motif_f3:\n",
    "    for name_of_motif in Motif_f3[dataset]:\n",
    "        if name_of_motif not in names_of_all_motifs:\n",
    "            names_of_all_motifs.append(str(name_of_motif))\n",
    "names_of_all_motifs=sorted(names_of_all_motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(args_e),len(names_of_all_motifs)))\n",
    "for i,d in enumerate(args_e):\n",
    "    for k,m in enumerate(names_of_all_motifs):\n",
    "        if m in Motif_f3[d]:\n",
    "            X[i][k] = Motif_f3[d][m]/sum(Motif_f3[d].values())  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
